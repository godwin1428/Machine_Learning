{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayees\n"
      ],
      "metadata": {
        "id": "nS2OfDj6FjSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('enjoysport.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = data.iloc[:, :-1]   # All columns except the last\n",
        "y = data.iloc[:, -1]    # Last column: EnjoySport\n",
        "\n",
        "# Get unique class labels\n",
        "classes = y.unique()\n",
        "\n",
        "# Calculate prior probabilities\n",
        "priors = {c: sum(y == c) / len(y) for c in classes}\n",
        "\n",
        "# Calculate conditional probabilities\n",
        "cond_probs = {}\n",
        "for col in X.columns:\n",
        "    cond_probs[col] = {}\n",
        "    for val in X[col].unique():\n",
        "        cond_probs[col][val] = {}\n",
        "        for c in classes:\n",
        "            count = sum((X[col] == val) & (y == c))\n",
        "            total = sum(y == c)\n",
        "            cond_probs[col][val][c] = count / total if total != 0 else 0\n",
        "\n",
        "# Naive Bayes prediction function\n",
        "def predict(instance):\n",
        "    results = {}\n",
        "    for c in classes:\n",
        "        prob = priors[c]\n",
        "        for col in X.columns:\n",
        "            val = instance[col]\n",
        "            prob *= cond_probs[col].get(val, {}).get(c, 0)\n",
        "        results[c] = prob\n",
        "    return max(results, key=results.get)\n",
        "\n",
        "# Test a sample instance\n",
        "test_instance = {'sky': 'Sunny', 'airtemp': 'Warm', 'humidity': 'High',\n",
        "                 'wind': 'Strong', 'water': 'Warm', 'forcast': 'Same'}\n",
        "\n",
        "print(\"Prediction:\", predict(test_instance))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCPz3IpvGaZB",
        "outputId": "4744b889-ecb4-4ee7-9e66-1cbea559788b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN"
      ],
      "metadata": {
        "id": "-5e9gheRHJN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "data=pd.read_csv('enjoysport.csv')\n",
        "X=data.iloc[:,:-1].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "y=data.iloc[:,-1]\n",
        "\n",
        "encoders=[LabelEncoder()for _ in X.columns]\n",
        "for i,col in enumerate(X.columns):\n",
        "        X.loc[:, col]=encoders[i].fit_transform(X[col]) # Use .loc for assignment\n",
        "y_enc=LabelEncoder()\n",
        "y=y_enc.fit_transform(y)\n",
        "\n",
        "knn=KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X,y)\n",
        "\n",
        "test=pd.DataFrame([['Sunny','Warm','High','Strong','Warm','Same']],columns=X.columns)\n",
        "\n",
        "# Convert test instance values to lowercase to match training data\n",
        "for col in test.columns:\n",
        "    test[col] = test[col].str.lower()\n",
        "\n",
        "for i,col in enumerate(test.columns):\n",
        "        test.loc[:, col]=encoders[i].transform(test[col]) # Use .loc for assignment\n",
        "\n",
        "print(\"prediction:\",y_enc.inverse_transform(knn.predict(test))[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hyoBeOAI-z4",
        "outputId": "fae97fc4-b402-463d-e1c3-0c9b2a049648"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction: yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "F0tRypykJNtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "x,y=make_classification(n_samples=1000,n_features=20,n_informative=15,n_redundant=5,random_state=42)\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
        "log_reg=LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(x_train,y_train)\n",
        "y_pred=log_reg.predict(x_test)\n",
        "cm=confusion_matrix(y_test,y_pred)\n",
        "print(pd.DataFrame(cm,columns=['Pred0','Pred1'],index=['True0','True1']))\n",
        "plt.matshow(cm)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "r9wkVzkfKMhd",
        "outputId": "cc3450b7-47af-48fc-d1d4-e51b2dba39b8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Pred0  Pred1\n",
            "True0     89     17\n",
            "True1     18     76\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 480x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "polynomial regression"
      ],
      "metadata": {
        "id": "OSlyJaDJLHcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv(\"enjoysport.csv\")\n",
        "\n",
        "# Separate features and target before encoding\n",
        "X = data.drop(\"enjoysport\", axis=1)\n",
        "y = data[\"enjoysport\"]\n",
        "\n",
        "# Encode categorical features in X\n",
        "le_features = {}\n",
        "for column in X.columns:\n",
        "    le = LabelEncoder()\n",
        "    X[column] = le.fit_transform(X[column])\n",
        "    le_features[column] = le # Store the encoder for later use\n",
        "\n",
        "# Encode target variable y\n",
        "le_target = LabelEncoder()\n",
        "y = le_target.fit_transform(y)\n",
        "\n",
        "# Polynomial feature transformation (degree=2)\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Polynomial Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set and round to 0 or 1 (binary classification)\n",
        "y_pred = np.round(model.predict(X_test))\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Predict for a new sample (e.g., Sunny Warm High Strong Cool Change)\n",
        "sample = ['Sunny', 'Warm', 'High', 'Strong', 'Cool', 'Change']\n",
        "sample_df = pd.DataFrame([sample], columns=[\"Sky\", \"AirTemp\", \"Humidity\", \"Wind\", \"Water\", \"Forecast\"])\n",
        "\n",
        "# Convert sample_df values to lowercase to match training data\n",
        "for col in sample_df.columns:\n",
        "    sample_df[col] = sample_df[col].str.lower()\n",
        "\n",
        "# Encode the sample using the fitted encoders\n",
        "sample_encoded = pd.DataFrame()\n",
        "for i, column in enumerate(X.columns): # Iterate through original column names\n",
        "    sample_encoded[column] = le_features[column].transform(sample_df.iloc[:, i])\n",
        "\n",
        "\n",
        "# Apply polynomial transformation to the encoded sample\n",
        "sample_poly = poly.transform(sample_encoded)\n",
        "\n",
        "prediction = np.round(model.predict(sample_poly))\n",
        "print(\"Prediction (1=Yes, 0=No):\", int(prediction[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HncZ44fSLXLx",
        "outputId": "6438a1b6-8f3f-4c43-9b81-43722d027a5d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Prediction (1=Yes, 0=No): 1\n"
          ]
        }
      ]
    }
  ]
}